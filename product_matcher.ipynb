{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed3c0dcd",
   "metadata": {},
   "source": [
    "## Short Summary\n",
    "Script name: product_matcher.py\n",
    "\n",
    "Purpose:\n",
    "\n",
    "Checks if a product description (from a PDF or other source) has already been processed and stored in the database‚Äîso you don‚Äôt repeat expensive extraction/AI work.\n",
    "\n",
    "Uses both exact matching (via hashes) and fuzzy matching (similarity threshold) for robust duplicate detection.\n",
    "\n",
    "Saves new results to cache after processing, so future requests are faster.\n",
    "\n",
    "Meant for use as a pre-processing step in a pipeline before you run costly scrapers, LLMs, or APIs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd9598d",
   "metadata": {},
   "source": [
    "# Product Cache Matching & Fuzzy Duplicate Detection\n",
    "\n",
    "This notebook contains tools to check whether a product description from your PDF or ETL workflow has already been processed.  \n",
    "It avoids duplicate processing using both exact (hash-based) and fuzzy (string-similarity) matching against your SQLite cache.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36fff74",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "- Python 3.8+\n",
    "- `sqlite3` (built-in)\n",
    "- `difflib` (built-in, for string similarity)\n",
    "- `database_setup.py` in your working directory (to import the hash generator)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6650817",
   "metadata": {},
   "source": [
    "Core Class with Dogstring and Comments (Code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96cdc79",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from datetime import datetime\n",
    "from database_setup import create_description_hash\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "class ProductMatcher:\n",
    "    \"\"\"\n",
    "    Class to manage product caching and duplicate detection using SQLite.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, db_path='product_cache.db'):\n",
    "        self.db_path = db_path\n",
    "\n",
    "    def get_connection(self):\n",
    "        \"Helper to get SQLite DB connection.\"\n",
    "        return sqlite3.connect(self.db_path)\n",
    "\n",
    "    def check_cache(self, oz_number, description, menge=\"\"):\n",
    "        \"\"\"\n",
    "        Checks for an **exact match** in the cache using a hash.\n",
    "        Returns product info if found, otherwise returns not found.\n",
    "        \"\"\"\n",
    "        desc_hash = create_description_hash(oz_number, description, menge)\n",
    "        conn = self.get_connection()\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute('''\n",
    "            SELECT * FROM extraction_cache \n",
    "            WHERE description_hash = ?\n",
    "        ''', (desc_hash,))\n",
    "        result = cursor.fetchone()\n",
    "        if result:\n",
    "            # Update last_accessed timestamp\n",
    "            cursor.execute('''\n",
    "                UPDATE extraction_cache \n",
    "                SET last_accessed = CURRENT_TIMESTAMP \n",
    "                WHERE description_hash = ?\n",
    "            ''', (desc_hash,))\n",
    "            conn.commit()\n",
    "            print(f\"‚úÖ Found in cache: {result[5]} - {result[6]}\")\n",
    "            conn.close()\n",
    "            return {\n",
    "                'found': True,\n",
    "                'scraped_brand': result[5],\n",
    "                'scraped_product_name': result[6], \n",
    "                'scraped_product_description': result[7],\n",
    "                'scraped_price': result[8],\n",
    "                'standard_category': result[9] if len(result) > 9 else 'Other',\n",
    "                'method': 'cache'\n",
    "            }\n",
    "        conn.close()\n",
    "        return {'found': False}\n",
    "\n",
    "    def fuzzy_search_similar(self, description):\n",
    "        \"\"\"\n",
    "        Finds **similar** product descriptions using fuzzy string matching.\n",
    "        Only considers previous extractions with valid brands.\n",
    "        Returns highest-confidence match above 70% similarity.\n",
    "        \"\"\"\n",
    "        conn = self.get_connection()\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute('''\n",
    "            SELECT original_description, scraped_brand, scraped_product_name, \n",
    "                   scraped_product_description, scraped_price, standard_category\n",
    "            FROM extraction_cache\n",
    "            WHERE scraped_brand NOT IN ('No Results', 'Processing Error', 'All Scraping Failed')\n",
    "        ''')\n",
    "        cached_items = cursor.fetchall()\n",
    "        matches = []\n",
    "        for item in cached_items:\n",
    "            cached_desc, brand, name, desc, price, category = item\n",
    "            similarity = SequenceMatcher(None, description.lower(), cached_desc.lower()).ratio()\n",
    "            if similarity > 0.7:\n",
    "                matches.append({\n",
    "                    'similarity': similarity,\n",
    "                    'scraped_brand': brand,\n",
    "                    'scraped_product_name': name,\n",
    "                    'scraped_product_description': desc,\n",
    "                    'scraped_price': price,\n",
    "                    'standard_category': category or 'Other',\n",
    "                    'original_description': cached_desc\n",
    "                })\n",
    "        conn.close()\n",
    "        if matches:\n",
    "            best_match = max(matches, key=lambda x: x['similarity'])\n",
    "            print(f\"üìä Found similar item: {best_match['similarity']:.1%} match\")\n",
    "            print(f\"   Original: {best_match['original_description'][:50]}...\")\n",
    "            print(f\"   Product: {best_match['scraped_brand']} - {best_match['scraped_product_name']}\")\n",
    "            return {\n",
    "                'found': True,\n",
    "                'method': 'fuzzy_match',\n",
    "                'confidence': best_match['similarity'],\n",
    "                **{k: v for k, v in best_match.items() if k != 'similarity'}\n",
    "            }\n",
    "        return {'found': False}\n",
    "\n",
    "    def save_to_cache(self, oz_number, description, menge, scraped_data):\n",
    "        \"\"\"\n",
    "        Saves product extraction results to cache.\n",
    "        Can overwrite existing records for that hash.\n",
    "        \"\"\"\n",
    "        desc_hash = create_description_hash(oz_number, description, menge)\n",
    "        conn = self.get_connection()\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute('''\n",
    "            INSERT OR REPLACE INTO extraction_cache \n",
    "            (oz_number, description_hash, original_description, menge,\n",
    "             scraped_brand, scraped_product_name, scraped_product_description, scraped_price, standard_category)\n",
    "            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "        ''', (\n",
    "            oz_number, desc_hash, description, menge,\n",
    "            scraped_data.get('scraped_brand', ''),\n",
    "            scraped_data.get('scraped_product_name', ''),\n",
    "            scraped_data.get('scraped_product_description', ''),\n",
    "            scraped_data.get('scraped_price', ''),\n",
    "            scraped_data.get('standard_category', 'Other')\n",
    "        ))\n",
    "        conn.commit()\n",
    "        conn.close()\n",
    "        print(\"üíæ Saved to cache for future use\")\n",
    "\n",
    "    def check_before_processing(self, oz_number, description, menge=\"\"):\n",
    "        \"\"\"\n",
    "        MAIN FUNCTION: Use before running expensive AI or scraping.\n",
    "        1. Checks for exact cache match.\n",
    "        2. If not found, checks for high-similarity fuzzy match.\n",
    "        3. If nothing is found, signals that new processing is needed.\n",
    "        \"\"\"\n",
    "        print(f\"\\nüîé Checking: {oz_number}\")\n",
    "        print(f\"   Description: {description[:60]}...\")\n",
    "        print(f\"   Menge: {menge}\")\n",
    "\n",
    "        # Step 1: Exact cache check\n",
    "        cache_result = self.check_cache(oz_number, description, menge)\n",
    "        if cache_result['found']:\n",
    "            return cache_result\n",
    "\n",
    "        # Step 2: Similar description check  \n",
    "        fuzzy_result = self.fuzzy_search_similar(description)\n",
    "        if fuzzy_result['found'] and fuzzy_result['confidence'] > 0.8:\n",
    "            print(\"üéØ High confidence match - using cached result\")\n",
    "            # Save this as exact match for future\n",
    "            self.save_to_cache(oz_number, description, menge, fuzzy_result)\n",
    "            return fuzzy_result\n",
    "\n",
    "        # Step 3: Not found - need to process\n",
    "        print(\"‚ùå Not found in cache - need to process with your script\")\n",
    "        return {'found': False, 'message': 'Process with your existing logic'}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e40dda4",
   "metadata": {},
   "source": [
    "## Example: Check and Cache a Product Extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7aa1a99",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "matcher = ProductMatcher()\n",
    "\n",
    "# Simulate a new product extraction line from your PDF/workflow\n",
    "result = matcher.check_before_processing(\n",
    "    oz_number=\"01.02.2024\",\n",
    "    description=\"Wireless Bluetooth headphones with noise cancellation\", \n",
    "    menge=\"5 Stk\"\n",
    ")\n",
    "print(f\"Result: {result}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d305273f",
   "metadata": {},
   "source": [
    "üí° **Tip:**  \n",
    "Always run this check before invoking your main (expensive) AI extraction!  \n",
    "If a match is found, you avoid unnecessary API calls.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d7146d",
   "metadata": {},
   "source": [
    "# Summary for Externals\n",
    "\n",
    "1. What does this do?\n",
    "\n",
    "Provides duplicate detection for your product extraction workflow.\n",
    "If an entry is already in your cache (exact or fuzzy match), you can reuse its data and save costs.\n",
    "\n",
    "2. Who should use it?\n",
    "\n",
    "Anyone running batch ETL, AI product extraction, or web scraping jobs that could create duplicates.\n",
    "\n",
    "3. Why is it important?\n",
    "\n",
    "Saves money, time, and avoids redundant work. Ensures clean, unique product data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67dce64",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
